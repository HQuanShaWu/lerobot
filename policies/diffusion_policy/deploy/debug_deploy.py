#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
[DEBUG VERSION] Oracle Policy Deployment
æ­¤ç‰ˆæœ¬å¢åŠ äº†å¤§é‡æ—¥å¿—ç”¨äºæ’æŸ¥â€œæœºæ¢°è‡‚ä¹±é£â€é—®é¢˜ã€‚
"""

from __future__ import annotations

import argparse
import logging
import os
import sys
import time
import json
from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Optional, Sequence, Tuple

import cv2
import numpy as np
import torch
import torch.nn.functional as F

import rclpy
from rclpy.node import Node
from sensor_msgs.msg import JointState
from std_msgs.msg import Bool

try:
    from piper_msgs.srv import Enable as EnableSrv
except ImportError:
    EnableSrv = None

from pika.gripper import Gripper

# --------------------------------------------------------------------------- #
# Constants & Config                                                          #
# --------------------------------------------------------------------------- #

ORACLE_ROOT = Path("/home/data/Project/Oracle") # è¯·ç¡®ä¿è·¯å¾„æ­£ç¡®
sys.path.append(str(ORACLE_ROOT))

# å¼•å…¥ LeRobot ç›¸å…³åº“
from lerobot.configs.types import FeatureType, NormalizationMode, PolicyFeature
from lerobot.policies.diffusion.configuration_diffusion import DiffusionConfig
from lerobot.policies.diffusion.modeling_diffusion import DiffusionPolicy
from lerobot.processor import PolicyAction, PolicyProcessorPipeline
from lerobot.processor.converters import policy_action_to_transition

# å…³èŠ‚é™åˆ¶ (å¼§åº¦)
JOINT_LIMITS: Sequence[tuple[float, float]] = [
    (-3.14, 3.14), (0.00, 2.00), (-2.00, 0.00),
    (-1.50, 1.80), (-1.30, 1.57), (-3.14, 3.14),
]
GRIPPER_MIN = 0.0
GRIPPER_MAX = 90.0 # å‡è®¾æ˜¯ 0-100 æˆ– 0-90 çš„æ•°å€¼

HOME_POS = [0.0, -0.035, 0.0, 0.0, 0.35, 0.0]

def clamp(value: float, bounds: Tuple[float, float]) -> float:
    lo, hi = bounds
    return float(max(lo, min(hi, value)))

@dataclass
class DeployArgs:
    checkpoint: Path
    device: str
    num_inference_steps: Optional[int]
    task_text: str
    rate: float
    gripper_port: str
    fisheye_index: Optional[int]
    realsense_serial: Optional[str]
    camera_width: int
    camera_height: int
    camera_fps: int

class OracleDeployNode(Node):
    def __init__(self, args: DeployArgs) -> None:
        super().__init__("oracle_realtime_controller")
        self.args = args
        # å¼ºåˆ¶ä¿®æ­£é¢‘ç‡ï¼šå¦‚æœä¼ å…¥ 0.5ï¼Œå¼ºåˆ¶æ”¹ä¸º 30Hz è¿›è¡Œæµ‹è¯•ï¼Œé¿å…ä½é¢‘å¯¼è‡´çš„æ§åˆ¶æ»å
        if self.args.rate < 1.0:
            self.get_logger().warn(f"âš ï¸ æ£€æµ‹åˆ°æä½çš„æ§åˆ¶é¢‘ç‡ ({self.args.rate} Hz)ã€‚å¼ºåˆ¶è¦†ç›–ä¸º 15.0 Hz è¿›è¡Œè°ƒè¯•ï¼")
            self.dt = 1.0 / 15.0
        else:
            self.dt = 1.0 / self.args.rate
            
        self.device = torch.device(args.device)
        torch.set_grad_enabled(False)

        # ROS Setup
        self.pub_joint = self.create_publisher(JointState, "/joint_ctrl_single", 10)
        self.pub_enable = self.create_publisher(Bool, "/enable_flag", 10)
        self.sub_joint = self.create_subscription(JointState, "/joint_states_single", self._joint_cb, 10)
        self.enable_client = self.create_client(EnableSrv, "/enable_srv") if EnableSrv else None

        self.expected_joint_names = [f"joint{i+1}" for i in range(6)]
        self.joint_index_map = None
        self.actual_positions = [0.0] * 6
        self.have_joint_sample = False
        self.latest_gripper = GRIPPER_MIN

        # Hardware Setup
        self.gripper = None
        self.fisheye_camera = None
        self.realsense_camera = None
        self._init_gripper()

        # Model Load
        self.cfg, self.preproc, self.postproc, self.model = self._load_policy_and_processors()
        self.model.eval()
        self.model.reset()

        self.timer = None
        self._shutdown_called = False
        self._last_command_time = time.monotonic()
        
        # è·å–å›¾åƒå°ºå¯¸ç”¨äº Resize æ£€æŸ¥
        self.image_shapes = {
            name: tuple(feature.shape)
            for name, feature in self.cfg.input_features.items()
            if name.startswith("observation.images")
        }

        self.get_logger().info("âœ… Debug Node Ready. Moving to HOME...")
        self._move_to_home()
        time.sleep(2.0)
        self.get_logger().info("ğŸš€ Starting Control Loop...")
        self.timer = self.create_timer(self.dt, self._tick)

    def _init_gripper(self) -> None:
        try:
            self.get_logger().info(f"Connecting Gripper on {self.args.gripper_port}...")
            gripper = Gripper(self.args.gripper_port)
            if not gripper.connect() or not gripper.enable():
                raise RuntimeError("Gripper connection failed")
            
            gripper.set_camera_param(self.args.camera_width, self.args.camera_height, self.args.camera_fps)
            if self.args.fisheye_index is not None:
                gripper.set_fisheye_camera_index(self.args.fisheye_index)
            if self.args.realsense_serial is not None:
                gripper.set_realsense_serial_number(self.args.realsense_serial)
                
            self.fisheye_camera = gripper.get_fisheye_camera()
            self.realsense_camera = gripper.get_realsense_camera()
            self.gripper = gripper
            self.get_logger().info(f"Hardware OK. Fisheye: {bool(self.fisheye_camera)}, RS: {bool(self.realsense_camera)}")
        except Exception as e:
            self.get_logger().error(f"Hardware Init Failed: {e}")
            sys.exit(1)

    def _load_policy_and_processors(self):
        ckpt_dir = Path(self.args.checkpoint)
        if (ckpt_dir / "pretrained_model").is_dir():
            ckpt_dir = ckpt_dir / "pretrained_model"
            
        self.get_logger().info(f"Loading Model from: {ckpt_dir}")
        with open(ckpt_dir / "config.json", "r") as f:
            cfg_dict = json.load(f)
        cfg_dict.pop("type", None)

        def _to_feature(feat_dict: dict) -> PolicyFeature:
            return PolicyFeature(type=FeatureType[feat_dict["type"]], shape=tuple(feat_dict.get("shape") or ()))

        if "input_features" in cfg_dict:
            cfg_dict["input_features"] = {k: _to_feature(v) for k, v in cfg_dict["input_features"].items()}
        if "output_features" in cfg_dict:
            cfg_dict["output_features"] = {k: _to_feature(v) for k, v in cfg_dict["output_features"].items()}
        if "normalization_mapping" in cfg_dict:
            cfg_dict["normalization_mapping"] = {k: NormalizationMode[v] for k, v in cfg_dict["normalization_mapping"].items()}
            
        cfg = DiffusionConfig(**cfg_dict)
        cfg.device = str(self.device)
        if self.args.num_inference_steps:
            cfg.num_inference_steps = int(self.args.num_inference_steps)

        overrides = {"device_processor": {"device": str(self.device)}}
        pre = PolicyProcessorPipeline.from_pretrained(ckpt_dir, config_filename="policy_preprocessor.json", overrides=overrides)
        post = PolicyProcessorPipeline.from_pretrained(ckpt_dir, config_filename="policy_postprocessor.json", overrides={"device_processor": {"device": "cpu"}}, to_transition=policy_action_to_transition)
        policy = DiffusionPolicy.from_pretrained(str(ckpt_dir), config=cfg)
        
        return cfg, pre, post, policy

    def _joint_cb(self, msg: JointState) -> None:
        if self.joint_index_map is None:
            name_to_index = {name: i for i, name in enumerate(msg.name)}
            self.joint_index_map = [name_to_index.get(name, i) for i, name in enumerate(self.expected_joint_names)]
            
        for out_idx, src_idx in enumerate(self.joint_index_map):
            if src_idx < len(msg.position):
                self.actual_positions[out_idx] = msg.position[src_idx]
        self.have_joint_sample = True

    def _frame_to_tensor(self, frame_bgr: np.ndarray, key: str) -> torch.Tensor:
        # Debug: æ£€æŸ¥å›¾åƒæ˜¯å¦æœ‰ä¿¡å·
        if frame_bgr is None or frame_bgr.size == 0:
            return torch.zeros(self.image_shapes.get(key), dtype=torch.float32)
        
        # ç®€å•çš„ç»Ÿè®¡é‡æ£€æŸ¥
        mean_val = np.mean(frame_bgr)
        if mean_val < 1.0:
            self.get_logger().warn(f"âš ï¸ Image {key} seems extremely dark (Mean: {mean_val:.2f})")
            
        rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)
        tensor = torch.from_numpy(rgb).permute(2, 0, 1).float() / 255.0
        
        target_shape = self.image_shapes.get(key)
        if target_shape:
            _, h, w = target_shape
            if tensor.shape[1:] != (h, w):
                tensor = F.interpolate(tensor.unsqueeze(0), size=(h, w), mode="bilinear", align_corners=False).squeeze(0)

        if not hasattr(self, "save_cnt"): self.save_cnt = 0
        self.save_cnt += 1
        if self.save_cnt % 30 == 0:
            # ä¿å­˜åˆ°å½“å‰ç›®å½•ï¼Œæ–‡ä»¶åå¸¦ä¸Š keyï¼Œçœ‹æ¸…æ¥šæ˜¯è°
            cv2.imwrite(f"debug_{key}.jpg", frame_bgr)
            print(f"ğŸ“¸ Saved debug image: debug_{key}.jpg")
        return tensor

    def _tick(self) -> None:
        if not self.have_joint_sample:
            self.get_logger().info("Waiting for joint states...")
            return

        start_time = time.time()
        
        # 1. Capture Data
        images = {}
        # å°è¯•æ•è·å›¾åƒï¼Œå¤±è´¥åˆ™ç”¨å…¨é»‘å¡«å……ä»¥é˜²æŠ¥é”™(ä»…è°ƒè¯•ç”¨)
        if self.fisheye_camera:
            ok, frame = self.fisheye_camera.get_frame()
            if ok and frame is not None:
                images["observation.images.fisheye_rgb"] = self._frame_to_tensor(frame, "observation.images.fisheye_rgb")
        if self.realsense_camera:
            ok, frame = self.realsense_camera.get_color_frame()
            if ok and frame is not None:
                images["observation.images.realsense_rgb"] = self._frame_to_tensor(frame, "observation.images.realsense_rgb")
        
        # æ„å»º State
        grip_val = 0.0
        if self.gripper:
            try:
                grip_val = self.gripper.get_gripper_distance()
            except: pass
        
        # === ğŸ•µï¸ DEBUG LOG 1: INPUT STATE ===
        # è¿™é‡Œæœ€å…³é”®ï¼šæ‰“å°å®é™…æ”¶åˆ°çš„å…³èŠ‚å€¼
        # å¦‚æœä½ çœ‹åˆ° [30.5, -10.2 ...] è¯´æ˜æ˜¯è§’åº¦ -> å®Œè›‹ï¼Œéœ€è¦è½¬å¼§åº¦
        # å¦‚æœä½ çœ‹åˆ° [0.52, -0.18 ...] è¯´æ˜æ˜¯å¼§åº¦ -> æ­£å¸¸
        raw_joints = list(self.actual_positions)
        state_vec = raw_joints + [grip_val]
        
        print(f"\n[{time.strftime('%H:%M:%S')}] === INPUT CHECK ===")
        print(f" > Raw Joints (Input): {[round(x, 4) for x in raw_joints]}")
        print(f" > Gripper Val: {grip_val}")
        
        if any(abs(x) > 3.2 for x in raw_joints):
            print("âš ï¸âš ï¸âš ï¸ WARNING: Joint value > 3.2 detected! Likely DEGREES. Dataset expects RADIANS.")
        
        # ç»„è£… Observation
        state_tensor = torch.tensor(state_vec, dtype=torch.float32)
        obs = {"observation.state": state_tensor}
        obs.update(images)

        # 2. Inference
        try:
            model_in = self.preproc(obs)
            
            # === ğŸ•µï¸ DEBUG LOG 2: NORMALIZED INPUT ===
            # æ£€æŸ¥å½’ä¸€åŒ–åçš„ State æ˜¯å¦åœ¨ [-2, 2] è¿™ç§åˆç†èŒƒå›´å†…
            # å¦‚æœè¿™é‡Œå‡ºç° 20, 30 è¿™ç§å¤§æ•°ï¼Œè¯´æ˜è¾“å…¥åˆ†å¸ƒå’Œè®­ç»ƒåˆ†å¸ƒä¸åŒ¹é…
            norm_state = model_in["observation.state"]
            if isinstance(norm_state, torch.Tensor):
                print(f" > Norm State (In Model): {norm_state[0].cpu().numpy().round(2)}")
            
            with torch.no_grad():
                action_out = self.model.select_action(model_in)
                
            result = self.postproc(action_out)
            action = result["action"] # Tensor
            
            if action.dim() > 1: action = action[0]
            command = action.detach().cpu().numpy().tolist()
            
            # === ğŸ•µï¸ DEBUG LOG 3: OUTPUT ACTION ===
            print(f" > Model Pred Action: {[round(x, 4) for x in command]}")
            
            # 3. Execution (With Safety Check)
            self._execute_command_safe(command)
            
            end_time = time.time()
            print(f" > Latency: {(end_time - start_time)*1000:.1f} ms")
            
        except Exception as e:
            self.get_logger().error(f"Inference Error: {e}")

    def _execute_command_safe(self, target):
        # ç®€å•çš„å®‰å…¨è¿‡æ»¤
        safe_target = []
        for i, val in enumerate(target[:6]):
            limit = JOINT_LIMITS[i]
            clipped = clamp(val, limit)
            safe_target.append(clipped)
            # å¦‚æœè£å‰ªå¹…åº¦å¾ˆå¤§ï¼Œè¯´æ˜æ¨¡å‹æƒ³å»éæ³•åŒºåŸŸ
            if abs(clipped - val) > 0.1:
                print(f"âš ï¸ Safety Clip J{i}: {val:.2f} -> {clipped:.2f}")

        # å‘å¸ƒ
        msg = JointState()
        msg.name = [f"joint{i+1}" for i in range(6)]
        msg.position = safe_target
        self.pub_joint.publish(msg)
        
        # Gripper
        if len(target) > 6:
            g_tgt = clamp(target[6], (GRIPPER_MIN, GRIPPER_MAX))
            if self.gripper:
                self.gripper.set_gripper_distance(g_tgt)

    def _move_to_home(self):
        # ç®€åŒ–ç‰ˆå›é›¶
        msg = JointState()
        msg.name = [f"joint{i+1}" for i in range(6)]
        msg.position = HOME_POS
        for _ in range(10):
            self.pub_joint.publish(msg)
            time.sleep(0.1)

    def shutdown(self):
        self.get_logger().info("Shutdown called.")
        if self.gripper: self.gripper.disconnect()

# Main Entry
def main():
    # æ¨¡æ‹Ÿå‚æ•°è§£æï¼Œä¸ºäº†æ–¹ä¾¿ç›´æ¥è¿è¡Œ
    parser = argparse.ArgumentParser()
    parser.add_argument("--checkpoint", type=str, required=True)
    parser.add_argument("--device", type=str, default="cuda")
    parser.add_argument("--rate", type=float, default=15.0) # é»˜è®¤æé«˜é¢‘ç‡
    parser.add_argument("--gripper-port", type=str, default="/dev/ttyUSB0")
    # ... å…¶ä»–å‚æ•°å¯æŒ‰éœ€è¡¥å…¨ï¼Œè¿™é‡Œä¸»è¦ä¸ºäº†è·‘èµ·æ¥
    
    # è¿™é‡Œçš„ hack æ˜¯ä¸ºäº†è®©ä½ å¤ç”¨ç°æœ‰çš„ shell è„šæœ¬ä¼ å‚
    # å¦‚æœ shell è„šæœ¬ä¼ äº† --task-text ç­‰å‚æ•°ï¼Œparser éœ€è¦å®šä¹‰å®ƒä»¬
    # ä¸ºäº†ç®€å•ï¼Œå»ºè®®åœ¨ shell è„šæœ¬é‡Œåªä¿ç•™æ ¸å¿ƒå‚æ•°ï¼Œæˆ–è€…åœ¨è¿™é‡Œè¡¥å…¨æ‰€æœ‰ arguments
    
    # è¡¥å…¨ args ä»¥é˜²æŠ¥é”™
    parser.add_argument("--task-text", type=str, default="")
    parser.add_argument("--num-inference-steps", type=int, default=10)
    parser.add_argument("--fisheye-index", type=int, default=None)
    parser.add_argument("--realsense-serial", type=str, default=None)
    parser.add_argument("--camera-width", type=int, default=640)
    parser.add_argument("--camera-height", type=int, default=480)
    parser.add_argument("--camera-fps", type=int, default=30)
    
    args = parser.parse_args()
    
    rclpy.init()
    node = OracleDeployNode(args)
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.shutdown()
        node.destroy_node()
        rclpy.shutdown()

if __name__ == "__main__":
    main()