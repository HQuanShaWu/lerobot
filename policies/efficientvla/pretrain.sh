# !/bin/bash
# æ ¹æ®æ•°æ®é›†é•¿åº¦è‡ªé€‚åº”å¢åŠ å…¨å±€æ­¥æ•°
set -e
export TOKENIZERS_PARALLELISM="false"
export PYTHONWARNINGS="ignore:The video decoding and encoding capabilities of torchvision are deprecated"

datasets=(
    "lerobot/ucsd_pick_and_place_dataset"  # ok
    "lerobot/stanford_kuka_multimodal_dataset"  # ok
    "lerobot/jaco_play"  # ok
    "trantor2nd/rheovla_dataset"  # ok
    # "lerobot/taco_play"  # use dataset.video_backend="pyav" and resize image to 224,224, ok
    # "lerobot/toto"       # dataset video time error
    # "lerobot/stanford_robocook"  # dataset video time error
    # "lerobot/utaustin_mutex"  # dataset video time error
    # "lerobot/stanford_hydra_dataset"  # dataset video time error
    # "lerobot/berkeley_autolab_ur5" # dataset video time error
    #  more...
)

NUM_EPOCHS=5
BATCH_SIZE=4
GRAD_ACCUM_STEPS=16

# è¿™æ˜¯ä¸€ä¸ªç´¯ç§¯è®¡æ•°å™¨ï¼Œä»…ç”¨äºæ—¥å¿—æ˜¾ç¤ºï¼Œä¸ä¼ ç»™è®­ç»ƒå‘½ä»¤
total_accumulated_steps=180000 

current_model_path="/home/img/project/lerobot/policies/efficientvla/train/mid_scale_horizon16_180ksteps_lora_rank32/checkpoints/180000/pretrained_model"
base_output_dir="policies/efficientvla/train/pretrain_mid_scale_horizon16_lora_rank32"

i=1

get_frames_cmd='
import sys
from lerobot.datasets.lerobot_dataset import LeRobotDataset
try:
    ds = LeRobotDataset(sys.argv[1])
    print(len(ds))
except Exception as e:
    print(0)
'

for dataset_name in "${datasets[@]}"; do

    echo "--------------------------------------------------"
    echo "æ­£åœ¨åˆ†ææ•°æ®é›†: $dataset_name ..."
    num_frames=$(python -c "$get_frames_cmd" "$dataset_name")
    
    if [ "$num_frames" -eq 0 ]; then
        echo "âŒ [ERROR] æ— æ³•è·å–æ•°æ®é›†å¤§å°æˆ–æ•°æ®é›†ä¸ºç©º: $dataset_name"
        exit 1
    fi
    
    # è®¡ç®—æœ¬æ¬¡éœ€è¦è®­ç»ƒçš„å¢é‡æ­¥æ•° (Delta Steps)
    delta_steps=$(python -c "print(int(($num_frames * $NUM_EPOCHS) / ($BATCH_SIZE)))")
    
    # è®¾ç½®ä¸€ä¸ªæœ€å°æ­¥æ•°ï¼Œé˜²æ­¢å› ä¸ºæ•°æ®é›†å¤ªå°å¯¼è‡´æ­¥æ•°è¿‡å°‘
    if [ "$delta_steps" -lt 100 ]; then
        delta_steps=100
    fi

    if [ "$dataset_name" == "trantor2nd/rheovla_dataset" ]; then
        delta_steps=200000
    fi
    
    # ä»…ç”¨äºæ—¥å¿—æ˜¾ç¤ºçš„ç´¯è®¡æ­¥æ•°
    total_accumulated_steps=$((total_accumulated_steps + delta_steps))

    seq_num=$(printf "%02d" $i)
    safe_name=${dataset_name//\//_}
    this_output_dir="${base_output_dir}_add${seq_num}_${safe_name}"

    echo "â–¶ åºåˆ—å·: $seq_num"
    echo "â–¶ æ•°æ®é›†å¸§æ•°: $num_frames"
    echo "â–¶ æœ¬è½®è®­ç»ƒæ—¶é•¿ (Delta Steps): $delta_steps"
    echo "â–¶ é¢„è®¡è®­ç»ƒåæ€»ç´¯è®¡æ­¥æ•° (Log only): $total_accumulated_steps"
    echo "--------------------------------------------------"

    # ä¿®æ”¹è¯´æ˜ï¼š
    # 1. --steps ä½¿ç”¨ delta_steps (è®­ç»ƒæ—¶é•¿)
    # 2. --save_freq ä½¿ç”¨ delta_steps (è·‘å®Œä¿å­˜)
    # 3. --policy.training_steps å¦‚æœæ˜¯ç”¨æ¥å®šä¹‰schedulerçš„æ€»é•¿åº¦ï¼Œä¹Ÿåº”è¯¥åŒ¹é…å½“å‰è®­ç»ƒæ—¶é•¿
    
    lerobot-train \
      --dataset.repo_id="$dataset_name" \
      --policy.pretrained_path="$current_model_path" \
      --output_dir="$this_output_dir" \
      --job_name="train_${seq_num}_${safe_name}" \
      --policy.type=efficientvla \
      --policy.device=cuda \
      --policy.lora_rank=32 \
      --policy.lora_alpha=64 \
      --policy.scale="medium" \
      --wandb.enable=false \
      --policy.push_to_hub=false \
      --batch_size=$BATCH_SIZE \
      --steps=${delta_steps} \
      --policy.training_steps=${delta_steps} \
      --save_freq=${delta_steps} \
      --gradient_accumulation_steps=$GRAD_ACCUM_STEPS \
      --dataset.video_backend="torchcodec" \
      --policy.repo_id="$current_model_path" 

    # è·¯å¾„æ£€æŸ¥é€»è¾‘æ›´æ–°ï¼š
    # å› ä¸ºæ˜¯åŠ è½½ pretrained_model æƒé‡è€Œé resume çŠ¶æ€ï¼Œè®­ç»ƒå™¨å†…éƒ¨æ­¥æ•°å¯èƒ½ä» 0 å¼€å§‹ã€‚
    # æ‰€ä»¥æ£€æŸ¥ç‚¹ç›®å½•ååº”è¯¥æ˜¯ delta_steps çš„æ•°å€¼ã€‚
    
    if [ -d "$this_output_dir/checkpoints/last/pretrained_model" ]; then
        current_model_path="$this_output_dir/checkpoints/last/pretrained_model"
    elif [ -d "$this_output_dir/checkpoints/${delta_steps}/pretrained_model" ]; then
        current_model_path="$this_output_dir/checkpoints/${delta_steps}/pretrained_model"
    else
        echo "âŒ [ERROR] Checkpoint æœªç”Ÿæˆï¼Œåœæ­¢è„šæœ¬ã€‚"
        echo "æ£€æŸ¥ç›®å½•: $this_output_dir/checkpoints/"
        # æ­¤æ—¶å¯ä»¥æ‰“å°ä¸€ä¸‹ç›®å½•ç»“æ„ä»¥ä¾¿è°ƒè¯•
        ls -R "$this_output_dir/checkpoints/"
        exit 1
    fi

    echo "âœ… åºåˆ— $seq_num å®Œæˆã€‚æ¨¡å‹æ›´æ–°ä¸º: $current_model_path"
    echo "ç­‰å¾… 5 ç§’å¼€å§‹ä¸‹ä¸€ä¸ªæ•°æ®é›†..."
    sleep 5

    i=$((i+1))

done

echo "ğŸ‰ æ‰€æœ‰æ•°æ®é›†è®­ç»ƒå®Œæˆï¼"